{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM estimation parameters\n",
    "LM_LIST = ['gpt2-small', 'neo-125m']\n",
    "N_SAMPLES_LIST = [512]\n",
    "N_TOKENS_LIST = [5]\n",
    "TEMPERATURE = 1.0\n",
    "\n",
    "# Cross-validation parameters\n",
    "N_SEEDS = 100\n",
    "N_FOLDS = 10\n",
    "\n",
    "# Required data paths\n",
    "DATA_FOLDER = \"../../data\"\n",
    "RESULTS_FOLDER = \"crossvalidation_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load estimates of responsive and anticipatory measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(f'{DATA_FOLDER}/psyling/aligned_with_estimates_23july.csv')\n",
    "data.columns = [col.replace('-', '_') for col in data.columns]\n",
    "\n",
    "# Define names of measures and predicted variables\n",
    "RATINGS = ['rating_mean', 'cloze_p_smoothed']\n",
    "ERP = ['N400', 'P600', 'ELAN', 'LAN', 'N400', 'EPNP', 'P600', 'PNP']\n",
    "RT = ['RTfirstfix', 'RTfirstpass', 'RTrightbound', 'self_paced_reading_time']\n",
    "VARIABILITY = ['entropy'] \n",
    "ALL_PREDICTED_VARIABLES = RATINGS + RT + ERP + VARIABILITY\n",
    "\n",
    "BASELINE_PREDICTORS = ['Subtlex_log10', 'context_length', 'length']\n",
    "BASELINE_PREDICTORS_RT = [\n",
    "    'Subtlex_log10', 'context_length', 'length', \n",
    "    'Subtlex_log10_prev', 'length_prev',\n",
    "    'Subtlex_log10_prev_prev', 'length_prev_prev'\n",
    "]\n",
    "\n",
    "EXACT_METRICS = ['prob', 'surprisal', 'expected_prob', 'entropy']\n",
    "SAMPLING_METRICS = ['decontextualised', 'expected_decontextualised', 'expected_seq_decontextualised', 'sequence_entropy']\n",
    "\n",
    "ANTICIPATORY = ['expected_prob', 'expected_decontextualised', 'expected_seq_decontextualised', 'sequence_entropy']\n",
    "RESPONSIVE = ['prob', 'decontextualised']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pairs(list):\n",
    "    \"\"\"\n",
    "    Generate all pairs of elements in a list.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for i in range(len(list)):\n",
    "        for j in range(i+1, len(list)):\n",
    "            pairs.append([list[i], list[j]])\n",
    "    return pairs\n",
    "\n",
    "def compute_rsquared(regressor, test_set, predicted_var):\n",
    "    \"\"\"\n",
    "    Compute R-squared for a given regressor and test set.\n",
    "    \"\"\"\n",
    "    y_pred = regressor.predict(test_set)\n",
    "    y_true = test_set[predicted_var]\n",
    "    residuals = y_true - y_pred\n",
    "    rss = np.sum(residuals**2)\n",
    "    tss = np.sum((y_true - np.mean(y_true))**2)\n",
    "    rsquared = 1 - rss / tss\n",
    "    return rsquared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target regressor vs. baseline regressor with _word frequency_, _length_, and _position_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e4aa1ee84749c9a9d0799cf9291c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0cc4d268d741eaa682604fb045ba2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b016b4c6472409789ac1aef9e6fd98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89cd824ef704db8872c9243612aaf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c43648e7a34ec6ac6132131cbf9e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aae95918ccf4717ac094c7181cb5e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a351d9d2e69b4fe1ba78288ce0242c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856c0c9c75b644b8af3f5b04c224c1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3029785f687347b880108ddc0e950edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f50655417004d1fbad1862499c0207e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fafcb0b3b54373b6eb656e0cb9aa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbae04da97e494281725ebb824d84fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for LM in LM_LIST:\n",
    "    LM_ = LM.replace('-', '_')\n",
    "    for N_SAMPLES in N_SAMPLES_LIST:\n",
    "        for N_TOKENS in N_TOKENS_LIST:\n",
    "            \n",
    "            # Define exact metric names for the current LM, N_SAMPLES, N_TOKENS (and TEMPERATURE)\n",
    "            EXACT_METRIC_NAMES = []\n",
    "            for exact_metric in EXACT_METRICS:\n",
    "                EXACT_METRIC_NAMES.append(f\"{exact_metric}_{LM_}\")\n",
    "                EXACT_METRIC_NAMES.append(f\"{exact_metric}_{LM_}_prev\")\n",
    "                EXACT_METRIC_NAMES.append(f\"{exact_metric}_{LM_}_prev_prev\")\n",
    "            # Define sampling metric names \n",
    "            SAMPLING_METRIC_NAMES = []\n",
    "            for sampling_metric in SAMPLING_METRICS:\n",
    "                SAMPLING_METRIC_NAMES.append(f\"{sampling_metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}\")\n",
    "                SAMPLING_METRIC_NAMES.append(f\"{sampling_metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}_prev\")\n",
    "                SAMPLING_METRIC_NAMES.append(f\"{sampling_metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}_prev_prev\")\n",
    "            # These are all metrics that will be used in the regression models\n",
    "            METRICS = EXACT_METRICS + SAMPLING_METRICS\n",
    "            METRIC_NAMES = EXACT_METRIC_NAMES + SAMPLING_METRIC_NAMES\n",
    "\n",
    "            # Data normalization\n",
    "            scaler = MinMaxScaler()\n",
    "            data_norm = data.copy()\n",
    "            data_norm[METRIC_NAMES] = scaler.fit_transform(data[METRIC_NAMES])\n",
    "            \n",
    "            \n",
    "            # Begin cross-validation\n",
    "            results = []\n",
    "            \n",
    "            for predicted_var in tqdm(ALL_PREDICTED_VARIABLES):\n",
    "\n",
    "                # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                if predicted_var in RT:\n",
    "                    baseline_predictors = BASELINE_PREDICTORS_RT\n",
    "                else:\n",
    "                    baseline_predictors = BASELINE_PREDICTORS\n",
    "\n",
    "                df_tmp = data_norm[[predicted_var] + baseline_predictors + METRIC_NAMES]\n",
    "\n",
    "                # N_SEEDS cross-validation runs\n",
    "                for seed in range(N_SEEDS):\n",
    "                    kf = KFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\n",
    "                    kf.get_n_splits(df_tmp) \n",
    "\n",
    "                    # N_FOLDS cross-validation\n",
    "                    for fold, (train_indices, test_indices) in enumerate(kf.split(df_tmp)):\n",
    "\n",
    "                        # Split data into training and test sets\n",
    "                        df_tmp_fold = df_tmp.iloc[train_indices]\n",
    "                        df_tmp_fold_test = df_tmp.iloc[test_indices]\n",
    "\n",
    "                        # Fit baseline regressor\n",
    "                        baseline_regressor = smf.ols(\n",
    "                            formula=f'{predicted_var} ~ {\" + \".join(baseline_predictors)}', \n",
    "                            data=df_tmp_fold\n",
    "                        ).fit()\n",
    "\n",
    "                        baseline_rsquared_test = compute_rsquared(baseline_regressor, df_tmp_fold_test, predicted_var)\n",
    "\n",
    "                        # Target regressors\n",
    "                        for metric in METRICS:\n",
    "                            # Exact metrics (no MC sampling)\n",
    "                            if metric in EXACT_METRICS:\n",
    "                                if predicted_var in RT:\n",
    "                                    # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                    predictor = \" + \".join([f\"{metric.replace('-', '_')}_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])\n",
    "                                else:\n",
    "                                    predictor = f\"{metric.replace('-', '_')}_{LM_}\"\n",
    "                            # Sampling metrics (MC sampling)\n",
    "                            elif metric in SAMPLING_METRICS:\n",
    "                                if predicted_var in RT:\n",
    "                                    # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                    predictor = \" + \".join([f\"{metric.replace('-', '_')}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])\n",
    "                                else:\n",
    "                                    predictor = f\"{metric.replace('-', '_')}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}\"\n",
    "                            else:\n",
    "                                raise ValueError(f\"Unknown metric: {metric}\")\n",
    "                            \n",
    "                            # Fit target regressor\n",
    "                            target_regressor = smf.ols(\n",
    "                                formula=f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + {predictor}', \n",
    "                                data=df_tmp_fold\n",
    "                            ).fit()\n",
    "\n",
    "                            # Compute R-squared on test set\n",
    "                            target_rsquared_test = compute_rsquared(target_regressor, df_tmp_fold_test, predicted_var)\n",
    "\n",
    "                            results.append({\n",
    "                                \"y\": predicted_var, \n",
    "                                \"metric\": metric,\n",
    "                                \"model\": LM, \n",
    "                                \"nsamples\": \"\" if metric in EXACT_METRICS else N_SAMPLES,\n",
    "                                \"ntokens\": \"\" if metric in EXACT_METRICS else N_TOKENS,\n",
    "                                \"temperature\": \"\" if metric in EXACT_METRICS else TEMPERATURE,\n",
    "                                \"fold\": f\"{seed}_{fold}\",\n",
    "                                \"rsquared_train\": target_regressor.rsquared, \n",
    "                                \"aic_train\": target_regressor.aic,\n",
    "                                \"bic_train\": target_regressor.bic,\n",
    "                                \"delta_rsquared_train\": target_regressor.rsquared - baseline_regressor.rsquared, \n",
    "                                \"delta_aic_train\": target_regressor.aic - baseline_regressor.aic,\n",
    "                                \"delta_bic_train\": target_regressor.bic - baseline_regressor.bic,\n",
    "                                \"rsquared_test\": target_rsquared_test,\n",
    "                                \"delta_rsquared_test\": target_rsquared_test - baseline_rsquared_test\n",
    "                            })\n",
    "                \n",
    "            results_df = pd.DataFrame(results)\n",
    "\n",
    "            results_df.to_csv(\n",
    "                f\"{RESULTS_FOLDER}/control_baseline_{LM_}_temp{str(TEMPERATURE).replace('.', '_')}_{N_SAMPLES}samples_{N_TOKENS}tokens_{N_SEEDS}x{N_FOLDS}fold.csv\",\n",
    "                index=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target regressor vs. baseline regressor with _surprisal_, _entropy_, _word frequency_, _length_, and _position_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a42fa0807441ffac986c6862df224d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eff7b0dd0f34eaaa70a4f9587e40578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117e0fc3eea840f9b783a9a865924353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439c3fe980a84e7aa1416d6243c25306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3772a298729f4ce89d88790ea9ba5529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6493c8d1d74bbaafa10a3e2f14ddce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a58191a22743a8bf4f0540a7bd1776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1d67a301254d21972b3e5a66c704c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbe1e693f954ef78b85bf54bf412cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcf86a768eb44ffb7d13d6a4950afff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa19416473a4018bc6cc75f16f544bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae3d7fbc2d84961a2b8739e044e07c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for LM in LM_LIST:\n",
    "    LM_ = LM.replace('-', '_')\n",
    "    for N_SAMPLES in N_SAMPLES_LIST:\n",
    "        for N_TOKENS in N_TOKENS_LIST:\n",
    "            \n",
    "            # Define exact metric names for the current LM, N_SAMPLES, N_TOKENS (and TEMPERATURE)\n",
    "            EXACT_METRIC_NAMES = []\n",
    "            for exact_metric in EXACT_METRICS:\n",
    "                EXACT_METRIC_NAMES.append(f\"{exact_metric}_{LM_}\")\n",
    "                EXACT_METRIC_NAMES.append(f\"{exact_metric}_{LM_}_prev\")\n",
    "                EXACT_METRIC_NAMES.append(f\"{exact_metric}_{LM_}_prev_prev\")\n",
    "            # Define sampling metric names \n",
    "            SAMPLING_METRIC_NAMES = []\n",
    "            for sampling_metric in SAMPLING_METRICS:\n",
    "                SAMPLING_METRIC_NAMES.append(f\"{sampling_metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}\")\n",
    "                SAMPLING_METRIC_NAMES.append(f\"{sampling_metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}_prev\")\n",
    "                SAMPLING_METRIC_NAMES.append(f\"{sampling_metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}_prev_prev\")\n",
    "            # These are all metrics that will be used in the regression models\n",
    "            METRICS = EXACT_METRICS + SAMPLING_METRICS\n",
    "            METRIC_NAMES = EXACT_METRIC_NAMES + SAMPLING_METRIC_NAMES\n",
    "\n",
    "            # Data normalization\n",
    "            scaler = MinMaxScaler()\n",
    "            data_norm = data.copy()\n",
    "            data_norm[METRIC_NAMES] = scaler.fit_transform(data[METRIC_NAMES])\n",
    "            \n",
    "            \n",
    "            # Begin cross-validation\n",
    "            results = []\n",
    "            \n",
    "            for predicted_var in tqdm(ALL_PREDICTED_VARIABLES):\n",
    "\n",
    "                # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                if predicted_var in RT:\n",
    "                    baseline_predictors = BASELINE_PREDICTORS_RT\n",
    "                else:\n",
    "                    baseline_predictors = BASELINE_PREDICTORS\n",
    "\n",
    "                df_tmp = data_norm[[predicted_var] + baseline_predictors + METRIC_NAMES]  \n",
    "\n",
    "                # N_SEEDS cross-validation runs\n",
    "                for seed in range(N_SEEDS):\n",
    "\n",
    "                    kf = KFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\n",
    "                    kf.get_n_splits(df_tmp) \n",
    "\n",
    "                    # N_FOLDS cross-validation\n",
    "                    for fold, (train_indices, test_indices) in enumerate(kf.split(df_tmp)):\n",
    "\n",
    "                        # Split data into training and test sets\n",
    "                        df_tmp_fold = df_tmp.iloc[train_indices]\n",
    "                        df_tmp_fold_test = df_tmp.iloc[test_indices]\n",
    "\n",
    "                        # Baseline predictors include surprisal and entropy\n",
    "                        if predicted_var in RT:\n",
    "                            # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                            formula = f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + {\" + \".join([f\"entropy_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])} + {\" + \".join([f\"surprisal_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])}'\n",
    "                        else:\n",
    "                            formula = f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + entropy_{LM_} + surprisal_{LM_}'\n",
    "                        \n",
    "                        # Fit baseline regressor\n",
    "                        baseline_regressor = smf.ols(\n",
    "                            formula=formula,\n",
    "                            data=df_tmp_fold\n",
    "                        ).fit()\n",
    "                        \n",
    "                        # Compute baseline regressor's R-squared on test set\n",
    "                        baseline_rsquared_test = compute_rsquared(baseline_regressor, df_tmp_fold_test, predicted_var)\n",
    "\n",
    "                        # Target regressors with anticipatory metrics\n",
    "                        for metric in ANTICIPATORY:\n",
    "\n",
    "                            # Collect target predictors\n",
    "                            if metric == 'expected_prob':  # this is the only anticipatory metric that does not depend on sampling\n",
    "                                if predicted_var in RT:\n",
    "                                    # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                    predictor = \" + \".join([f\"{metric}_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])\n",
    "                                else:\n",
    "                                    predictor = f\"{metric}_{LM_}\"\n",
    "                            else:\n",
    "                                if predicted_var in RT:\n",
    "                                    # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                    predictor = \" + \".join([f\"{metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])\n",
    "                                else:\n",
    "                                    predictor = f\"{metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}\"\n",
    "\n",
    "                            # Collect all predictors: here, we substitute entropy with the target anticipatory metric\n",
    "                            if predicted_var in RT:\n",
    "                                # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                formula = f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + {predictor} + {\" + \".join([f\"surprisal_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])}'\n",
    "                            else:\n",
    "                                formula = f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + {predictor} + surprisal_{LM_}'\n",
    "                            \n",
    "                            # Fit target regressor with anticipatory metric\n",
    "                            target_regressor_anticipatory = smf.ols(\n",
    "                                formula=formula,\n",
    "                                data=df_tmp_fold\n",
    "                            ).fit()\n",
    "\n",
    "                            # Compute R-squared on test set\n",
    "                            anticip_rsquared_test = compute_rsquared(target_regressor_anticipatory, df_tmp_fold_test, predicted_var)\n",
    "\n",
    "                            results.append({\n",
    "                                \"y\": predicted_var, \n",
    "                                \"metric\": metric,\n",
    "                                \"model\": LM,\n",
    "                                \"nsamples\": \"\" if metric == 'expected_prob' else N_SAMPLES,\n",
    "                                \"ntokens\": \"\" if metric == 'expected_prob' else N_TOKENS,\n",
    "                                \"temperature\": \"\" if metric == 'expected_prob' else TEMPERATURE,\n",
    "                                \"fold\": f\"{seed}_{fold}\", \n",
    "                                \"rsquared_train\": target_regressor_anticipatory.rsquared,\n",
    "                                \"aic_train\": target_regressor_anticipatory.aic,\n",
    "                                \"bic_train\": target_regressor_anticipatory.bic,\n",
    "                                \"delta_rsquared_train\": target_regressor_anticipatory.rsquared - baseline_regressor.rsquared, \n",
    "                                \"delta_aic_train\": target_regressor_anticipatory.aic - baseline_regressor.aic,\n",
    "                                \"delta_bic_train\": target_regressor_anticipatory.bic - baseline_regressor.bic,\n",
    "                                \"rsquared_test\": anticip_rsquared_test,\n",
    "                                \"delta_rsquared_test\": anticip_rsquared_test - baseline_rsquared_test,\n",
    "                            })\n",
    "\n",
    "\n",
    "                        # Target regressors with responsive metrics\n",
    "                        for metric in RESPONSIVE:\n",
    "\n",
    "                            # Collect target predictors\n",
    "                            if metric == 'prob':  # this is the responsive metric that does not depend on sampling\n",
    "                                if predicted_var in RT:\n",
    "                                    # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                    predictor = \" + \".join([f\"{metric}_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])\n",
    "                                else:\n",
    "                                    predictor = f\"{metric}_{LM_}\"\n",
    "                            else:\n",
    "                                if predicted_var in RT:\n",
    "                                    # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                    predictor = \" + \".join([f\"{metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])\n",
    "                                else:\n",
    "                                    predictor = f\"{metric}_{LM_}_{N_SAMPLES}_{N_TOKENS}_{str(TEMPERATURE).replace('.', '_')}\"\n",
    "\n",
    "                            # Collect all predictors: here, we substitute surprisal with the target responsive metric\n",
    "                            if predicted_var in RT:\n",
    "                                # For reading times, include values at t-1 and t-2 (spillover effects)\n",
    "                                formula = f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + {\" + \".join([f\"entropy_{LM_}{timestep}\" for timestep in [\"\", \"_prev\", \"_prev_prev\"]])} + {predictor}'\n",
    "                            else:\n",
    "                                formula = f'{predicted_var} ~ {\" + \".join(baseline_predictors)} + entropy_{LM_} + {predictor}'\n",
    "\n",
    "                            target_regressor_responsive = smf.ols(\n",
    "                                formula=formula,\n",
    "                                data=df_tmp_fold\n",
    "                            ).fit()\n",
    "\n",
    "                            resp_rsquared_test = compute_rsquared(target_regressor_responsive, df_tmp_fold_test, predicted_var)\n",
    "\n",
    "                            results.append({\n",
    "                                \"y\": predicted_var, \n",
    "                                \"metric\": metric,\n",
    "                                \"model\": LM,\n",
    "                                \"nsamples\": \"\" if metric == 'prob' else N_SAMPLES,\n",
    "                                \"ntokens\": \"\" if metric == 'prob' else N_TOKENS,\n",
    "                                \"temperature\": \"\" if metric == 'prob' else TEMPERATURE,\n",
    "                                \"fold\": f\"{seed}_{fold}\", \n",
    "                                \"rsquared_train\": target_regressor_responsive.rsquared,\n",
    "                                \"aic_train\": target_regressor_responsive.aic,\n",
    "                                \"bic_train\": target_regressor_responsive.bic,\n",
    "                                \"delta_rsquared_train\": target_regressor_responsive.rsquared - baseline_regressor.rsquared,\n",
    "                                \"delta_aic_train\": target_regressor_responsive.aic - baseline_regressor.aic,\n",
    "                                \"delta_bic_train\": target_regressor_responsive.bic - baseline_regressor.bic,\n",
    "                                \"rsquared_test\": resp_rsquared_test,\n",
    "                                \"delta_rsquared_test\": resp_rsquared_test - baseline_rsquared_test\n",
    "                            })\n",
    "\n",
    "                \n",
    "            results = pd.DataFrame(results)\n",
    "\n",
    "            results.to_csv(\n",
    "                f\"{RESULTS_FOLDER}/surprisal_entropy_baseline_{LM_}_temp{str(TEMPERATURE).replace('.', '_')}_{N_SAMPLES}samples_{N_TOKENS}tokens_{N_SEEDS}x{N_FOLDS}fold.csv\",\n",
    "                index=False\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
